{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "eI_n5qvmvas7"
   },
   "source": [
    "import scipy.io\n",
    "import scipy\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch,torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WxOwgMnsvas_"
   },
   "source": [
    "## Fixed params\n",
    "eff=0.5\n",
    "nu=1\n",
    "PL_d0_dB = 31.67\n",
    "alpha = 2\n",
    "Z_stdDev = 2\n",
    "W=1e6\n",
    "N0=1e-14\n",
    "D=50\n",
    "\n",
    "scale_factor=1e7\n",
    "numChReal=1000000\n",
    "P_AP=2\n",
    "p_max=0.001"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "m7O_Lt8GvatA"
   },
   "source": [
    "input_data_folder='../input_data'\n",
    "output_data_folder='../output/pure_DL_models/'\n",
    "tensor_board_folder='../runs/pureDL'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "IpwB8FinvatA"
   },
   "source": [
    "def power_to_time_tensor(p_i,gh,gt,D,W,eff,P_AP,N0):\n",
    "    t_i=D/(W*torch.log2(1+(p_i*gt)/(N0*W)))\n",
    "    req_harv_energy= t_i*p_i\n",
    "    t0=torch.max(req_harv_energy/(eff*P_AP*gh),dim=1)[0]\n",
    "    #tot_time=torch.sum(t_i,dim=1)+t0\n",
    "    return scale_factor*torch.cat((t0.unsqueeze(dim=1),t_i),dim=1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "03I5BRSIvatB"
   },
   "source": [
    "match = scipy.io.loadmat(input_data_folder+'/channel_gains.mat')\n",
    "test_ind=np.load(input_data_folder+'/test_ind.npy')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "p_max",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9EHStl6HvatC",
    "outputId": "5d4eaacc-1a04-485a-c38c-5ba815e59233"
   },
   "source": [
    "dnn_result=[]\n",
    "for num_of_user in range(2,5,2):\n",
    "    ## DNN Arch  ##\n",
    "    class TimeNet(nn.Module):\n",
    "\n",
    "        def __init__(self):\n",
    "            super(TimeNet, self).__init__()\n",
    "\n",
    "            self.layer1 = nn.Linear(2*num_of_user,8*num_of_user)\n",
    "            self.layer2 = nn.Linear(8*num_of_user,8*num_of_user)\n",
    "            self.layer3 = nn.Linear(8*num_of_user,8*num_of_user)\n",
    "            self.layer4 = nn.Linear(8*num_of_user,4*num_of_user)\n",
    "            self.layer5 = nn.Linear(4*num_of_user,4*num_of_user)\n",
    "            self.output = nn.Linear(4*num_of_user,num_of_user+1)\n",
    "\n",
    "        def forward(self,input_x):\n",
    "\n",
    "            x1_1 = F.relu(self.layer1(input_x))\n",
    "            x = F.relu(self.layer2(x1_1))\n",
    "            x = F.relu(self.layer3(x))\n",
    "            x = F.relu(self.layer4(x))\n",
    "            x = F.relu(self.layer5(x))\n",
    "            x=torch.abs(self.output(x))\n",
    "\n",
    "            return x\n",
    "    class PowerNet(nn.Module):\n",
    "\n",
    "        def __init__(self):\n",
    "            super(PowerNet, self).__init__()\n",
    "\n",
    "            self.layer1 = nn.Linear(2*num_of_user,8*num_of_user)\n",
    "            self.layer2 = nn.Linear(8*num_of_user,8*num_of_user)\n",
    "            self.layer3 = nn.Linear(8*num_of_user,8*num_of_user)\n",
    "            self.layer4 = nn.Linear(8*num_of_user,4*num_of_user)\n",
    "            self.layer5 = nn.Linear(4*num_of_user,4*num_of_user)\n",
    "            self.output = nn.Linear(4*num_of_user,num_of_user)\n",
    "\n",
    "        def forward(self,input_x):\n",
    "\n",
    "            x1_1 = F.relu(self.layer1(input_x))\n",
    "            x = F.relu(self.layer2(x1_1))\n",
    "            x = F.relu(self.layer3(x))\n",
    "            x = F.relu(self.layer4(x))\n",
    "            x = F.relu(self.layer5(x))\n",
    "            x=p_max*(scale_factor/100)*F.sigmoid(self.output(x))\n",
    "\n",
    "            return x\n",
    "\n",
    "    # read labels\n",
    "    mat = scipy.io.loadmat(input_data_folder+'/result_compare_N014'+'_PAP'+str(P_AP)+'_M'+str(num_of_user)+'_pmax'+str(p_max)+'.mat')\n",
    "    outs=mat['tot_time_MRTTMA4'].T\n",
    "    outs=outs*scale_factor\n",
    "\n",
    "    mat_pow=scipy.io.loadmat(input_data_folder+'/powers_N014'+'_PAP'+str(P_AP)+'_pmax'+str(p_max)+'_M'+str(num_of_user)+'.mat')\n",
    "    outs_pow=mat_pow['p_i'].T\n",
    "    outs_pow=outs_pow*scale_factor/100\n",
    "\n",
    "    gh=match['gh_arr'][0:num_of_user,0:numChReal]\n",
    "    gt=match['gt_arr'][0:num_of_user,0:numChReal]\n",
    "\n",
    "    ins=np.concatenate((gh,gt)).T\n",
    "    indicies=np.arange(len(ins))\n",
    "    remaning_ind=list(set(indicies)-set(test_ind))\n",
    "\n",
    "    ins2=ins[remaning_ind]\n",
    "    outs2=outs[remaning_ind]\n",
    "    outs_pow2=outs_pow[remaning_ind]\n",
    "\n",
    "    X_test=ins[test_ind]\n",
    "    y_test=outs[test_ind]\n",
    "    y_pow_test=outs_pow[test_ind]\n",
    "    idx_test=list(test_ind)\n",
    "\n",
    "    X_train, X_val, y_train, y_val, y_pow_train, y_pow_val,idx_train,idx_val = train_test_split( ins2,outs2,outs_pow2, remaning_ind, test_size=0.01, random_state=42)\n",
    "\n",
    "    # Scale\n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train)\n",
    "    X_val = ss.transform(X_val)\n",
    "    X_test = ss.transform(X_test)\n",
    "\n",
    "    #Dataset & DataLoder\n",
    "    torch_dataset = TensorDataset(torch.tensor(X_train.astype(np.float32)), torch.tensor(y_train.astype(np.float32)),torch.tensor(y_pow_train.astype(np.float32)))\n",
    "    val_torch_dataset = TensorDataset(torch.tensor(X_val.astype(np.float32)), torch.tensor(y_val.astype(np.float32)), torch.tensor(y_pow_val.astype(np.float32)))\n",
    "\n",
    "\n",
    "\n",
    "    train_data_loader = DataLoader(torch_dataset, batch_size=32)\n",
    "    val_data_loader = DataLoader(val_torch_dataset,batch_size=1)\n",
    "\n",
    "\n",
    "    ## TRAINING\n",
    "    # default `log_dir` is \"runs\" - we'll be more specific here\n",
    "    writer = SummaryWriter(tensor_board_folder+'/onlyDNN_abs_time_N014'+'_PAP'+str(P_AP)+'_M'+str(num_of_user)+'_pmax'+str(p_max))\n",
    "    writer_pow = SummaryWriter(tensor_board_folder+'/onlyDNN_abs_pow_N014'+'_PAP'+str(P_AP)+'_M'+str(num_of_user)+'_pmax'+str(p_max))\n",
    "    NO_EPOCHS = 20\n",
    "\n",
    "    val_loss_best=10000000\n",
    "    val_loss_best_pow=10000000\n",
    "\n",
    "    model_time = TimeNet()\n",
    "    model_pow = PowerNet()\n",
    "\n",
    "    optimizer = Adam(model_time.parameters(),lr=1e-4)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min')\n",
    "\n",
    "    optimizer_pow = Adam(model_pow.parameters(),lr=1e-4)\n",
    "    scheduler_pow = ReduceLROnPlateau(optimizer_pow, 'min')\n",
    "\n",
    "    loss_fn = nn.MSELoss()\n",
    "    loss_fn_pow = nn.MSELoss()\n",
    "   \n",
    "    for epoch_idx in range(NO_EPOCHS):\n",
    "            model_time.train()\n",
    "            model_pow.train()\n",
    "            epoch_loss = 0\n",
    "            len_batches = 0\n",
    "            epoch_loss_pow = 0\n",
    "\n",
    "            for ii,sample in enumerate(tqdm(train_data_loader)):\n",
    "\n",
    "                local_inp, local_tgt,local_tgt_pow = sample\n",
    "                output = model_time(local_inp)\n",
    "                output_pow = model_pow(local_inp)\n",
    "                loss = loss_fn(output,local_tgt)\n",
    "                loss_pow = loss_fn_pow(output_pow,local_tgt_pow)\n",
    "\n",
    "\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                optimizer_pow.zero_grad()\n",
    "                loss_pow.backward()\n",
    "                optimizer_pow.step()\n",
    "\n",
    "                #print(f'Train Epoch: {epoch_idx}, Batch: {ii*len(local_tgt)},Loss: {loss}')\n",
    "                epoch_loss += loss.detach().numpy()\n",
    "                epoch_loss_pow += loss_pow.detach().numpy()\n",
    "\n",
    "            # Validation phase\n",
    "            model_time.eval()\n",
    "            val_loss = 0\n",
    "            model_pow.eval()\n",
    "            val_loss_pow = 0\n",
    "\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for jj, val_sample in enumerate(val_data_loader):\n",
    "                    local_inp, local_tgt, local_tgt_pow= val_sample\n",
    "                    output = model_time(local_inp)\n",
    "                    val_loss += loss_fn(output,local_tgt)\n",
    "\n",
    "                    output_pow = model_pow(local_inp)\n",
    "                    val_loss_pow += loss_fn(output_pow,local_tgt_pow)\n",
    "\n",
    "                val_loss /= (jj+1)\n",
    "                val_loss_pow /= (jj+1)\n",
    "\n",
    "\n",
    "            if val_loss < val_loss_best:\n",
    "                    val_loss_best=val_loss\n",
    "                    torch.save(model_time, output_data_folder+'/model_sep_N'+str(num_of_user)+'.pt')\n",
    "                    #X_test_inverse = torch.Tensor(ss.inverse_transform(X_test))\n",
    "                    test_output = model_time((torch.tensor(X_test.astype(np.float32))))\n",
    "                    test_output_pow = model_pow((torch.tensor(X_test.astype(np.float32))))\n",
    "\n",
    "\n",
    "            writer.add_scalar('val_loss',\n",
    "                        val_loss,\n",
    "                        epoch_idx)\n",
    "\n",
    "            writer.add_scalar('training loss',\n",
    "                        epoch_loss / (ii+1),\n",
    "                        epoch_idx)\n",
    "            writer_pow.add_scalar('val_loss',\n",
    "                        val_loss_pow,\n",
    "                        epoch_idx)\n",
    "\n",
    "            writer_pow.add_scalar('training loss',\n",
    "                        epoch_loss_pow / (ii+1),\n",
    "                        epoch_idx)\n",
    "\n",
    "    np.save(output_data_folder+'/tot_time_DNN_N014'+'_PAP'+str(P_AP)+'_M'+str(num_of_user)+'_pmax'+str(p_max),(test_output/scale_factor).detach().numpy())\n",
    "    np.save(output_data_folder+'/pow_DNN_N014'+'_PAP'+str(P_AP)+'_M'+str(num_of_user)+'_pmax'+str(p_max),(test_output_pow/scale_factor*100).detach().numpy())\n",
    "    dnn_result.append((test_output/scale_factor).sum(axis=1).mean().detach().item())\n",
    "#np.save(output_data_folder+'/all_tot_times_N014'+'_PAP'+str(P_AP)+'_M'+str(num_of_user)+'_pmax'+str(p_max),[powmu_result,maxeh_result,chi_result,dnn_result])\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "eeSTOJ9WvatF"
   },
   "source": [
    "import torch\n",
    "def outage_calc(t_0,t_i,p_i,gh,gt,D,W,eff,P_AP,N0):\n",
    "    energy_harvested=t_0*eff*P_AP*gh\n",
    "\n",
    "    time_to_comsume_energy=energy_harvested/p_i\n",
    "\n",
    "    if t_i>=time_to_comsume_energy:\n",
    "        data_sent=time_to_comsume_energy*W*torch.log2(1+(p_i*gt)/(N0*W))\n",
    "    else:\n",
    "        data_sent=t_i*W*torch.log2(1+(p_i*gt)/(N0*W))\n",
    "    #print('Data Sent' + str(data_sent))\n",
    "    outage=D-data_sent\n",
    "\n",
    "    return outage"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
