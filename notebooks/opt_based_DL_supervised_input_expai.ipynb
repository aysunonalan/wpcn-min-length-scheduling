{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "M4LrJyZCjzQ6"
   },
   "source": [
    "import scipy.io\n",
    "import scipy\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch, torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_regression as MIR"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JA0DOBk7jzQ8"
   },
   "source": [
    "## Fixed params\n",
    "eff = 0.5\n",
    "nu = 1\n",
    "PL_d0_dB = 31.67\n",
    "alpha = 2\n",
    "Z_stdDev = 2\n",
    "W = 1e6\n",
    "N0 = 1e-14\n",
    "D = 50\n",
    "\n",
    "scale_factor = 1e7\n",
    "numChReal = 1000000\n",
    "## params changing based on input file\n",
    "P_AP = 2\n",
    "p_max = 0.001\n",
    "\n",
    "train_data_size = 100\n",
    "num_of_user = 4"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QnPJJS97jzQ8"
   },
   "source": [
    "input_data_folder='../input_data'\n",
    "output_data_folder='../output/opt_DL_models/'\n",
    "tensor_board_folder='../runs/optDL'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cqBtJvJrjzQ8"
   },
   "source": [
    "def power_to_time_tensor(p_i, gh, gt, D, W, eff, P_AP, N0):\n",
    "    t_i = D / (W * torch.log2(1 + (p_i * gt) / (N0 * W)))\n",
    "    req_harv_energy = t_i * p_i\n",
    "    t0 = torch.max(req_harv_energy / (eff * P_AP * gh), dim=1)[0]\n",
    "    # tot_time=torch.sum(t_i,dim=1)+t0\n",
    "    return scale_factor * torch.cat((t0.unsqueeze(dim=1), t_i), dim=1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def early_stopping(validation_loss_prev, validation_loss, counter,min_delta = 0.05):\n",
    "\n",
    "    if (validation_loss - validation_loss_prev) < min_delta:\n",
    "        counter +=1\n",
    "    else:\n",
    "        counter = 0\n",
    "    return counter\n",
    "      "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YgvGcK2hjzQ8"
   },
   "source": [
    "##  LOAD DATA\n",
    "match = scipy.io.loadmat(input_data_folder + \"/channel_gains.mat\")\n",
    "test_ind=np.load(input_data_folder+'/test_ind.npy')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XAc4TkYLjzQ9",
    "outputId": "64122cbc-a503-486c-e8c4-39128a7a85af"
   },
   "source": [
    "dnn_result = []\n",
    "val_loss_list = []\n",
    "# Load data\n",
    "mat = scipy.io.loadmat(\n",
    "    input_data_folder\n",
    "    + \"/result_compare_N014\"\n",
    "    + \"_PAP\"\n",
    "    + str(P_AP)\n",
    "    + \"_M\"\n",
    "    + str(num_of_user)\n",
    "    + \"_pmax\"\n",
    "    + str(p_max)\n",
    "    + \".mat\"\n",
    ")\n",
    "outs = mat[\"tot_time_MRTTMA4\"].T\n",
    "outs = outs * scale_factor\n",
    "\n",
    "gh = match[\"gh_arr\"][0:num_of_user, 0:numChReal]\n",
    "gt = match[\"gt_arr\"][0:num_of_user, 0:numChReal]\n",
    "\n",
    "gamma = gh * gt * eff * P_AP / (W * N0)\n",
    "alpha = np.abs(scipy.special.lambertw(np.exp(-1) * (gamma - 1), k=0) + 1)\n",
    "\n",
    "ins = np.concatenate((gh, gt, alpha, gamma)).T\n",
    "indicies = np.arange(len(ins))\n",
    "\n",
    "remaning_ind = list(set(indicies) - set(test_ind))\n",
    "\n",
    "ins2 = ins[remaning_ind]\n",
    "outs2 = outs[remaning_ind]\n",
    "\n",
    "X_test = ins[test_ind]\n",
    "y_test = outs[test_ind]\n",
    "idx_test = list(test_ind)\n",
    "\n",
    "X_train, X_val, y_train, y_val, idx_val, idx_test = train_test_split(\n",
    "    ins2, outs2, remaning_ind, test_size=0.01, random_state=42\n",
    ")\n",
    "\n",
    "# Scale\n",
    "ss = StandardScaler()\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_val = ss.transform(X_val)\n",
    "X_test = ss.transform(X_test)\n",
    "\n",
    "# Feature Selection\n",
    "mi = MIR(X_train[0:5000, :], np.sum(y_train[0:5000, :], 1))\n",
    "feature_index = np.argsort(mi)\n",
    "feat_size = 3 * num_of_user\n",
    "\n",
    "feature_index = np.argsort(mi)\n",
    "feature_index = feature_index[-1 * feat_size :]\n",
    "\n",
    "## DNN Arch  ##\n",
    "class OptNetMIR(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(OptNetMIR, self).__init__()\n",
    "\n",
    "        self.layer1 = nn.Linear(feat_size, 8 * num_of_user)\n",
    "        self.layer2 = nn.Linear(8 * num_of_user, 8 * num_of_user)\n",
    "        self.layer3 = nn.Linear(8 * num_of_user, 8 * num_of_user)\n",
    "        self.layer4 = nn.Linear(8 * num_of_user, 4 * num_of_user)\n",
    "        self.layer5 = nn.Linear(4 * num_of_user, 4 * num_of_user)\n",
    "\n",
    "        self.output = nn.Linear(4 * num_of_user, num_of_user)\n",
    "\n",
    "    def forward(self, input_x, input_x_inv):\n",
    "\n",
    "        x1_1 = F.relu(self.layer1(input_x))\n",
    "        x = F.relu(self.layer2(x1_1))\n",
    "        x = F.relu(self.layer3(x))\n",
    "        x = F.relu(self.layer4(x))\n",
    "        x = F.relu(self.layer5(x))\n",
    "\n",
    "        x = p_max * F.sigmoid(self.output(x))\n",
    "        x2 = power_to_time_tensor(\n",
    "            x,\n",
    "            input_x_inv[:, 0:num_of_user],\n",
    "            input_x_inv[:, num_of_user : 2 * num_of_user],\n",
    "            D,\n",
    "            W,\n",
    "            eff,\n",
    "            P_AP,\n",
    "            N0,\n",
    "        )\n",
    "\n",
    "        return x2\n",
    "\n",
    "# Dataset & DataLoder\n",
    "torch_dataset = TensorDataset(\n",
    "    torch.tensor(X_train[0:train_data_size, :].astype(np.float32)),\n",
    "    torch.tensor(y_train[0:train_data_size, :].astype(np.float32)),\n",
    ")\n",
    "val_torch_dataset = TensorDataset(\n",
    "    torch.tensor(X_val.astype(np.float32)), torch.tensor(y_val.astype(np.float32))\n",
    ")\n",
    "\n",
    "train_data_loader = DataLoader(torch_dataset, batch_size=32)\n",
    "val_data_loader = DataLoader(val_torch_dataset, batch_size=1)\n",
    "\n",
    "## TRAINING\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter(\n",
    "    tensor_board_folder\n",
    "    + \"/feat3N_trainsize\"\n",
    "    + str(train_data_size)\n",
    "    + \"sup_MIR_3N_feature\"\n",
    "    + \"_M\"\n",
    "    + str(num_of_user)\n",
    "    + \"_PAP\"\n",
    "    + str(P_AP)\n",
    "    + \"_pmax\"\n",
    "    + str(p_max)\n",
    ")\n",
    "NO_EPOCHS = 20\n",
    "\n",
    "val_loss_best = 10000000\n",
    "\n",
    "model = OptNetMIR()\n",
    "optimizer = Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = ReduceLROnPlateau(optimizer, \"min\")\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "for epoch_idx in range(NO_EPOCHS):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    len_batches = 0\n",
    "    for ii, sample in enumerate(tqdm(train_data_loader)):\n",
    "\n",
    "        local_inp, local_tgt = sample\n",
    "        local_inp_inv = torch.Tensor(ss.inverse_transform(local_inp))\n",
    "        output = model(local_inp[:, feature_index], local_inp_inv)\n",
    "        loss = loss_fn(output, local_tgt)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.detach().numpy()\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    counter = 0\n",
    "    with torch.no_grad():\n",
    "        val_loss_prev=val_loss\n",
    "        for jj, val_sample in enumerate(val_data_loader):\n",
    "            local_inp, local_tgt = val_sample\n",
    "            local_inp_inv = torch.Tensor(ss.inverse_transform(local_inp))\n",
    "\n",
    "            output = model(local_inp[:, feature_index], local_inp_inv)\n",
    "            val_loss += loss_fn(output, local_tgt)\n",
    "\n",
    "        val_loss /= jj + 1\n",
    "\n",
    "    if val_loss < val_loss_best:\n",
    "        val_loss_best = val_loss\n",
    "        # torch.save(model, output_data_folder+'/feat3N_model_N'+str(num_of_user)+'.pt')\n",
    "        X_test_inverse = torch.Tensor(ss.inverse_transform(X_test))\n",
    "        test_output = model(\n",
    "            (torch.tensor(X_test[:, feature_index].astype(np.float32))),\n",
    "            X_test_inverse,\n",
    "        )\n",
    "        if early_stopping(val_loss_prev, val_loss, counter) > 5:\n",
    "            break\n",
    "   \n",
    "\n",
    "    # writer.add_scalar('val_loss',val_loss,epoch_idx)\n",
    "    # writer.add_scalar('training loss', epoch_loss / (ii+1),epoch_idx)\n",
    "\n",
    "val_loss_list.append(val_loss)\n",
    "# np.save(output_data_folder+'/trainsize'+str(train_data_size)+'tot_time_DNN_N014'+'_PAP'+str(P_AP)+'_M'+str(num_of_user)+'_pmax'+str(p_max),(test_output/scale_factor).detach().numpy())\n",
    "# dnn_result.append((test_output/scale_factor).sum(axis=1).mean().detach().item())\n",
    "# np.save(output_data_folder+'/trainsize'+str(train_data_size)+'all_tot_times_N014'+'_PAP'+str(P_AP)+'_M'+str(num_of_user)+'_pmax'+str(p_max),dnn_result)\n",
    "\n",
    "#np.save(\"drive/MyDrive/magazine_paper/val_loss_results_july_2024/expai\", val_loss_list)\n",
    "\n",
    "    "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "nRisUOYLrTam"
   },
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
